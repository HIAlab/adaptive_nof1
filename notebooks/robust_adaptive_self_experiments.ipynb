{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e2cfa3-2298-433f-9194-f0d82ab5e284",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Robust methods for intervention selections using Thompson Sampling\n",
    "This notebooks explores robust methods for using thompson sampling in Self-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb5327-443b-466e-9c23-a6b96fc084b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports & preperation code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy\n",
    "from adaptive_nof1.models import Model, SelfExperimentationModel\n",
    "from adaptive_nof1.basic_types import Outcome, History\n",
    "\n",
    "from adaptive_nof1 import SeriesOfSimulationsRunner, SeriesOfSimulationsData\n",
    "from adaptive_nof1.policies import (\n",
    "    FixedPolicy,\n",
    "    ThompsonSampling,\n",
    "    BalancedThompsonSampling,\n",
    "    ClippedThompsonSampling,\n",
    "    ComposedPolicy,\n",
    ")\n",
    "from adaptive_nof1.inference import *\n",
    "from adaptive_nof1.helpers import *\n",
    "from adaptive_nof1.series_of_simulations_runner import simulate_configurations\n",
    "from adaptive_nof1.metrics import SimpleRegret, RegretAgainstOtherConfiguration\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c23bc-862c-408c-82f1-6b97c2cf1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions to do the analyses\n",
    "def switch_config(config):\n",
    "    config = config.copy()\n",
    "    config[\"policy\"] = \"FixedPolicy\"\n",
    "    return config\n",
    "\n",
    "\n",
    "def plot_regret_against_fixed(calculated_series, config_to_simulation_data):\n",
    "    models = numpy.unique([s[\"configuration\"][\"model\"] for s in calculated_series])\n",
    "    for model in models:\n",
    "        plt.figure()\n",
    "        plt.title(model)\n",
    "        SeriesOfSimulationsData.plot_lines(\n",
    "            [\n",
    "                series[\"result\"]\n",
    "                for series in calculated_series\n",
    "                if series[\"configuration\"][\"model\"] == model\n",
    "            ],\n",
    "            [\n",
    "                RegretAgainstOtherConfiguration(\n",
    "                    configuration_transform_function=switch_config,\n",
    "                    config_to_simulation_data=config_to_simulation_data,\n",
    "                    outcome_name=\"outcome\",\n",
    "                )\n",
    "            ],\n",
    "            legend_position=(0, 1.5),\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b9b8bea-e66b-455c-a6e1-e7844305a283",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Methodology\n",
    "\n",
    "We start with a simple simulation model, and then add different features with make learning harder, namely:\n",
    "- changes in baseline\n",
    "- correlation in the outcomes\n",
    "- spikes in the data.\n",
    "After analysing how the algorithms behave, we will test different additions to it.\n",
    "## Simulation Model\n",
    "We assume ordinal outcomes between 0 and 5 for our simulation model.\n",
    "It is assumed that this ordinal measure is achieved by mapping a continuous outcome onto 5 point scale. The decision boundaries are chosen by dividing the probability mass of a $N(0,1)$ distribution into equal parts. They are -0.84, -0.25, 0.25 and 0.84.\n",
    "In the most basic case, the outcome is defined as: $outcome(a) = baseline + \\text{effect}(a)$.\n",
    "\n",
    "## Policies\n",
    "We start with three policies for comparison:\n",
    "- Fixed, Balanced Design\n",
    "- Thompson Sampling with Beta Model\n",
    "- Thompson Sampling with Conjugate Normal Model\n",
    "\n",
    "## Bayesian Models\n",
    "### BetaModel\n",
    "This is currently used in the Self-E app.\n",
    "Let $c$ be the number of the condition.\n",
    "This model estimates the probability $p$ of an intervention beeing sucessfull as $p \\sim Beta(a_c + 1, b_c + 1)$, where $a = count(outcome(c) \\geq average(outcome))$ \"number of sucesses\", and $b = count(outcome(c) < average(outcome)$ \"number of failures\".\n",
    "Then, it uses sampling to estimate the probability $Beta(a_1,b_1) > Beta(a_2, b_2)$\n",
    "Since $a_c$ and $b_c$ are 0 if there is no data $Beta(1, 1)$ it the prior distribution.\n",
    "\n",
    "### ConjugateNormalModel\n",
    "This model models each outcome as a Normal random variable $N(\\mu_c,\\sigma_c)$.  \n",
    "It uses the normal inverse gamma function $ING(mean, l, alpha, beta)$ as prior, because this is the conjugate prior to the normal distribution and therefore makes updating very easy.\n",
    "The used priors are shown below, and are set to be weakly informative. The prior predictive simulation shows how the predicted values range from 0 to 5.\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "We evaluate different metrics that could be interesting:  \n",
    "Regret is defined as the difference in the sum of outcomes between to policies. For our case, we want to compare against the fixed schedule.\n",
    "We define the regret as  \n",
    "$Regret(policy) = \\sum_{t}^T Reward(t)_{fixed} - \\sum_{t}^T Reward(t)_{adaptive}$.\n",
    "\n",
    "We evaluate:\n",
    "- Mean Regret\n",
    "- Median Regret\n",
    "- 0.25 and 0.75 quantiles of regret\n",
    "- Span between best and worst regret (per participant)\n",
    "- Best Intervention Identification: Percentage of Participants getting the correct prediction at timepoint t\n",
    "  - For fixed, this will be determined by difference in means between both conditions\n",
    "  - For the Bayesian Models, the preferred condition will be determined by the maximum probability of selection at the last timepoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7085cc4-717d-4f1e-8178-e532635fdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for setting priors\n",
    "conjugate_normal_model_priors = {\n",
    "    \"mean\": 2.5,\n",
    "    \"l\": 0.5,\n",
    "    \"alpha\": 10,\n",
    "    \"beta\": 10,\n",
    "}\n",
    "## Print posterior distribution of priors\n",
    "model = ConjugateNormalModel(**conjugate_normal_model_priors)\n",
    "plt.hist(\n",
    "    model.sample_normal_inverse_gamma(\n",
    "        model.mean, model.l, model.alpha, model.beta, 10000, 1\n",
    "    ),\n",
    "    bins=100,\n",
    ")\n",
    "plt.title(\"Prior predictive distribution for ConjugateNormalModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab754c03-23ff-4b23-9b42-7ee333b6b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for calculating evaluation\n",
    "def calculate_recommendations(calculated_series):\n",
    "    data = []\n",
    "    for result in calculated_series:\n",
    "        series_of_simulations_data = result[\"result\"]\n",
    "        for simulation in series_of_simulations_data.simulations:\n",
    "            observation = simulation.history.observations[-1]\n",
    "            if \"probabilities\" in observation.debug_data:\n",
    "                # print(observation.debug_data[\"probabilities\"])\n",
    "                probabilities = observation.debug_data[\"probabilities\"]\n",
    "                data.append(\n",
    "                    {\n",
    "                        **simulation.configuration,\n",
    "                        \"p_assigned_intervention_1\": probabilities[1],\n",
    "                        \"p_assigned_intervention_0\": probabilities[0],\n",
    "                        \"recommendation\": numpy.argmax(probabilities),\n",
    "                    }\n",
    "                )\n",
    "                # print(data)\n",
    "            else:\n",
    "                df = simulation.history.to_df()\n",
    "                data.append(\n",
    "                    {\n",
    "                        **simulation.configuration,\n",
    "                        \"recommendation\": numpy.argmax(\n",
    "                            df.groupby(\"treatment\")[\"outcome\"].mean()\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "    recommended_interventions_df = pandas.DataFrame(data)\n",
    "    return recommended_interventions_df\n",
    "\n",
    "\n",
    "def generate_result_table(calculated_series):\n",
    "    # Things for the table: mean regret, median regret, 25% regret, 75% regret, bias when fitting linear regression model\n",
    "    metrics = [\n",
    "        RegretAgainstOtherConfiguration(\n",
    "            configuration_transform_function=switch_config,\n",
    "            config_to_simulation_data=config_to_simulation_data,\n",
    "            outcome_name=\"outcome\",\n",
    "        ),\n",
    "    ]\n",
    "    series = [entry[\"result\"] for entry in calculated_series]\n",
    "    scores = SeriesOfSimulationsData.score_data(\n",
    "        series,\n",
    "        metrics,\n",
    "    )\n",
    "    scores = scores[scores[\"t\"] == scores[\"t\"].max()]\n",
    "    table = pandas.DataFrame()\n",
    "    table[\"mean_regret\"] = scores.groupby([\"policy\", \"model\"])[\"score\"].mean()\n",
    "    table[\"median_regret\"] = scores.groupby([\"policy\", \"model\"])[\"score\"].median()\n",
    "    table[\".25 quantile regret\"] = scores.groupby([\"policy\", \"model\"])[\n",
    "        \"score\"\n",
    "    ].quantile(0.25)\n",
    "    table[\".75 quantile regret\"] = scores.groupby([\"policy\", \"model\"])[\n",
    "        \"score\"\n",
    "    ].quantile(0.75)\n",
    "    table[\".95 quantile regret\"] = scores.groupby([\"policy\", \"model\"])[\n",
    "        \"score\"\n",
    "    ].quantile(0.95)\n",
    "    table[\".05 quantile regret\"] = scores.groupby([\"policy\", \"model\"])[\n",
    "        \"score\"\n",
    "    ].quantile(0.05)\n",
    "    table[\"Span of regret\"] = (\n",
    "        scores.groupby([\"policy\", \"model\"])[\"score\"].max()\n",
    "        - scores.groupby([\"policy\", \"model\"])[\"score\"].min()\n",
    "    )\n",
    "    recommended_interventions_df = calculate_recommendations(calculated_series)\n",
    "    table[\"p_assigned_intervention_1_mean\"] = recommended_interventions_df.groupby(\n",
    "        [\"policy\", \"model\"]\n",
    "    )[\"p_assigned_intervention_1\"].mean()\n",
    "    table[\"recommendation_mean\"] = recommended_interventions_df.groupby(\n",
    "        [\"policy\", \"model\"]\n",
    "    )[\"recommendation\"].mean()\n",
    "    return table.swaplevel(\"policy\", \"model\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323b84e-0f48-4184-8035-5bc8626824c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare simulation constants\n",
    "N_INTERVENTIONS = 2\n",
    "LENGTH = 40\n",
    "N_PATIENTS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66cce7-89c4-4a3d-9dc9-7d18f8586744",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scenario 1:\n",
    "Let's start with a simple scenario: $baseline \\sim Normal(0, 1)$, Treatment effects differ.\n",
    "We look at 3 different effects:\n",
    "- Scenario 1.1: -1 // Treatment worsens outcome\n",
    "- Scenario 1.2: 0  // Treatment does not change outcome\n",
    "- Scenario 1.3: 1  // Treatment improves outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e7ed4e-d239-419a-93e4-29c58b85ab75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define models\n",
    "data_generating_model_1_1 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, -1],\n",
    "    baseline_model=\"noise\",\n",
    "    baseline_config={\"variance\": 1},\n",
    ")\n",
    "data_generating_model_1_2 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 0],\n",
    "    baseline_model=\"noise\",\n",
    "    baseline_config={\"variance\": 1},\n",
    ")\n",
    "data_generating_model_1_3 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    baseline_model=\"noise\",\n",
    "    baseline_config={\"variance\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959b576-630e-48d9-bfa5-8cb07da8314c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define policies\n",
    "fixed_policy = FixedPolicy(number_of_actions=N_INTERVENTIONS)\n",
    "linear_ts = ThompsonSampling(\n",
    "    inference_model=ConjugateNormalModel(**conjugate_normal_model_priors),\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "beta_ts = ThompsonSampling(\n",
    "    inference_model=BetaModel(),\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "regression_ts = ThompsonSampling(\n",
    "    inference_model=BayesianLinearRegressionModel(\n",
    "        mean=numpy.array(\n",
    "            [\n",
    "                conjugate_normal_model_priors[\"mean\"],\n",
    "                conjugate_normal_model_priors[\"mean\"],\n",
    "            ]\n",
    "        ),\n",
    "        v=numpy.eye(N_INTERVENTIONS) * 100,\n",
    "        alpha=conjugate_normal_model_priors[\"alpha\"],\n",
    "        beta=conjugate_normal_model_priors[\"beta\"],\n",
    "    ),\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471aa0c6-ae5a-48ca-969f-481e3ee69505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full crossover study\n",
    "study_designs = {\n",
    "    \"n_patients\": [N_PATIENTS],\n",
    "    \"policy\": [fixed_policy, linear_ts, beta_ts, regression_ts],\n",
    "    \"model_from_patient_id\": [\n",
    "        data_generating_model_1_1,\n",
    "        data_generating_model_1_2,\n",
    "        data_generating_model_1_3,\n",
    "    ],\n",
    "}\n",
    "configurations = generate_configuration_cross_product(study_designs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6f882-4ee5-4ca6-a20e-de205e02e064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calculated_series, config_to_simulation_data = simulate_configurations(\n",
    "    configurations, LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b651ab9-f2c6-4384-af68-47a479058acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result_table(calculated_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a209e-1223-44a8-b71f-1de1a1ea846c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_regret_against_fixed(calculated_series, config_to_simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d5821b-0f42-435e-94e8-224331b0f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_allocations_for_calculated_series(calculated_series):\n",
    "    panels = [series[\"result\"].plot_allocations() for series in calculated_series]\n",
    "    for panel, i in zip(panels, range(len(panels))):\n",
    "        panel.opts(\n",
    "            title=f\"{calculated_series[i]['configuration']['policy']}, {calculated_series[i]['configuration']['model']}\",\n",
    "            fontsize={\"title\": \"80%\"},\n",
    "        )\n",
    "    return holoviews.Layout(panels).cols(1)\n",
    "\n",
    "\n",
    "plot_allocations_for_calculated_series(calculated_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63519139-b2b1-4c24-bc50-d0272d673ffd",
   "metadata": {},
   "source": [
    "### Results\n",
    "- Both models perform well: Note that -40 is the perfect regret for 1 as an intervention effect, and the models achieve roundabout half of that\n",
    "- Conjugate Normal Model performs a little bit better on average, but has some higher variability\n",
    "\n",
    "### Identified problems\n",
    "- None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6099fb-3d3d-42c7-9008-95f688132d92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scenario 2: Baseline Changes\n",
    "Most likely, our baseline will not be constant over time. Let's see how this affects the performance of our algorithms.\n",
    "For this, we now simulate the baseline\n",
    "\n",
    "- as a linear function\n",
    "- as a gaussian process:\n",
    "$c$ is the correlation coefficient, and $\\sigma$ the variance of the process  \n",
    "$y_t = c y_{t-1} + \\epsilon$  \n",
    "$\\epsilon \\sim N(0, \\sigma)$  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2047a-d6a0-41dc-83d8-6fada2cdd68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_generating_model_2_1 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": 1, \"max\": -1, \"name\": \"Ramp Down\"},\n",
    ")\n",
    "data_generating_model_2_2 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    ")\n",
    "data_generating_model_2_3 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    baseline_model=\"random_walk\",\n",
    "    baseline_config={\n",
    "        \"min\": -1,\n",
    "        \"max\": 1,\n",
    "        \"variance\": 0.1,\n",
    "        \"correlation\": 0.99,\n",
    "        \"name\": \"RandomWalk1\",\n",
    "    },\n",
    ")\n",
    "data_generating_model_2_4 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    baseline_model=\"random_walk\",\n",
    "    baseline_config={\n",
    "        \"min\": -2,\n",
    "        \"max\": 2,\n",
    "        \"variance\": 0.3,\n",
    "        \"correlation\": 0.999,\n",
    "        \"name\": \"RandomWalk2\",\n",
    "    },\n",
    ")\n",
    "data_generating_model_2_5 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 0],\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": 1, \"max\": -1, \"name\": \"Ramp Down\"},\n",
    ")\n",
    "data_generating_model_2_6 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 0],\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ecdc5-5763-420e-bf2a-30baa66f5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_designs = {\n",
    "    \"n_patients\": [N_PATIENTS],\n",
    "    \"policy\": [\n",
    "        fixed_policy,\n",
    "        linear_ts,\n",
    "        beta_ts,\n",
    "        ClippedThompsonSampling(\n",
    "            inference_model=ConjugateNormalModel(**conjugate_normal_model_priors),\n",
    "            number_of_actions=N_INTERVENTIONS,\n",
    "        ),\n",
    "    ],\n",
    "    \"model_from_patient_id\": [\n",
    "        data_generating_model_2_1,\n",
    "        data_generating_model_2_2,\n",
    "        data_generating_model_2_3,\n",
    "        data_generating_model_2_4,\n",
    "        data_generating_model_2_5,\n",
    "        data_generating_model_2_6,\n",
    "    ],\n",
    "}\n",
    "configurations = generate_configuration_cross_product(study_designs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fce76-495c-453a-ae42-0de857f68714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes some time\n",
    "calculated_series, config_to_simulation_data = simulate_configurations(\n",
    "    configurations, LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b36cae-b029-4991-a36f-3a8ccc53fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some baselines:\n",
    "baseline_names = [\"Ramp Down\", \"Ramp Up\", \"RandomWalk1\", \"RandomWalk2\"]\n",
    "\n",
    "\n",
    "def print_baseline(baseline_name):\n",
    "    for series in calculated_series:\n",
    "        if baseline_name in series[\"configuration\"][\"model\"]:\n",
    "            series[\"result\"].simulations[0].history.to_df().plot.line(\n",
    "                x=\"t\", y=\"baseline\"\n",
    "            )\n",
    "            plt.title(baseline_name)\n",
    "            return\n",
    "\n",
    "\n",
    "for baseline_name in baseline_names:\n",
    "    print_baseline(baseline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f391062-12f8-49db-b7db-b7ee95062c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result_table(calculated_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1a3e7-4fa2-4c3e-851f-5faf787528b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regret_against_fixed(calculated_series, config_to_simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e292a-83ed-478e-958a-39f31e3659a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allocations_for_calculated_series(calculated_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615ed8a-4fc5-465e-aa19-5d7d1a8c584a",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- Similar results on Regret for both models\n",
    "- See \"SelfExperimentationModel[[0, 1], Ramp Up, 0, 0]\", \"Beta Model\":\n",
    "  - Even though we have a positive treatment effect, ~20% of the cases converge on the baseline treatment\n",
    "- See allocation plots for SEM[0, 0], Ramp Up\n",
    "  - both models converge heavily towards one condition at around t=20, which is 50% good or bad.\n",
    "\n",
    "### Identified problems:\n",
    "- Models converge if there is no treatment effect\n",
    "- Models converge on the wrong treatment effect (mostly present in Beta Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9646c-0a64-4d78-927a-2472e06c3747",
   "metadata": {},
   "source": [
    "## Scenario 3: Correlated Outcomes\n",
    "Most likely, our outcomes will be correlated over time. Let's see how this affects the performance of our algorithms.\n",
    "\n",
    "For this we now simulate the outcomes as:\n",
    "$outcome_t = correlationfactor \\cdot outcome_{t-1} + \\epsilon$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01eee7-b0e0-4b8d-8a31-2650e0f90378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generating_model_3_1 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 1], correlation=0.3\n",
    ")\n",
    "data_generating_model_3_2 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 1], correlation=-0.3\n",
    ")\n",
    "data_generating_model_3_3 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 1], correlation=0.7\n",
    ")\n",
    "data_generating_model_3_4 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 1], correlation=-0.7\n",
    ")\n",
    "data_generating_model_3_5 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 0], correlation=-0.7\n",
    ")\n",
    "data_generating_model_3_6 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 0], correlation=-0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6894da-cda5-4745-a7c0-711f8d088789",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_designs = {\n",
    "    \"n_patients\": [N_PATIENTS],\n",
    "    \"policy\": [fixed_policy, linear_ts, beta_ts],\n",
    "    \"model_from_patient_id\": [\n",
    "        data_generating_model_3_1,\n",
    "        data_generating_model_3_2,\n",
    "        data_generating_model_3_3,\n",
    "        data_generating_model_3_4,\n",
    "        data_generating_model_3_5,\n",
    "        data_generating_model_3_6,\n",
    "    ],\n",
    "}\n",
    "configurations = generate_configuration_cross_product(study_designs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a911f-b79a-4e21-863d-00acc4afc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes some time\n",
    "calculated_series, config_to_simulation_data = simulate_configurations(\n",
    "    configurations, LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31e71e-bea5-4013-9cb8-56352307a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot an outcome to see it's correlation:\n",
    "calculated_series[2][\"result\"].simulations[0].history.to_df().plot(\n",
    "    x=\"t\", y=\"continuous_outcome\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954938c6-c312-4259-abd9-aba941729987",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result_table(calculated_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b592d55-ebfb-4281-a019-19cc792a81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regret_against_fixed(calculated_series, config_to_simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d8fe2-b14f-4bad-a33e-35416b3f4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allocations_for_calculated_series(calculated_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86629d14-41b0-4100-ad15-70971361797e",
   "metadata": {},
   "source": [
    "### Result \n",
    "- The results in regret differ, which should not be because the models perform better but because we change the simulation environment. No sever bad effects can be seen by the different correlation factors.\n",
    "\n",
    "### Identified problems:\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c43ac-6625-4799-9fa8-5e99919b6a8d",
   "metadata": {},
   "source": [
    "## Scenario 4: Random Spikes\n",
    "\n",
    "The outcome in a Self-Experiment is likely not only influenced by the intervention, but by other unobserved events.\n",
    "We simulate this by introducing spikes into the data. A spike is a datapoint where we set the outcome to 1 regardless of the sampled condition.\n",
    "We simulate by using a probability $p_{spike}$ which says how likely a spike at a current datapoint is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb44a9-e956-44ac-89ae-018fb0f66e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generating_model_4_1 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    spike_probability=1.0 / 7,\n",
    ")\n",
    "data_generating_model_4_2 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    spike_probability=2.0 / 7,\n",
    ")\n",
    "data_generating_model_4_3 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 1], spike_probability=3.0 / 7\n",
    ")\n",
    "data_generating_model_4_4 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id, intervention_effects=[0, 0], spike_probability=2.0 / 7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58268a96-87d0-412d-a674-1447d0df776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_designs = {\n",
    "    \"n_patients\": [N_PATIENTS],\n",
    "    \"policy\": [fixed_policy, linear_ts, beta_ts],\n",
    "    \"model_from_patient_id\": [\n",
    "        data_generating_model_4_1,\n",
    "        data_generating_model_4_2,\n",
    "        data_generating_model_4_3,\n",
    "        data_generating_model_4_4,\n",
    "    ],\n",
    "}\n",
    "configurations = generate_configuration_cross_product(study_designs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a03885-52af-48af-ab40-402ca02a74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_series, config_to_simulation_data = simulate_configurations(\n",
    "    configurations, LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e32ea-f1fa-4bbc-9ade-ec79ec051eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result_table(calculated_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f041d2-9d8a-45df-805b-20b3efd90909",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regret_against_fixed(calculated_series, config_to_simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a862a-cef2-4161-a732-ac22c10bdb46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_allocations_for_calculated_series(calculated_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684efe2a-87dd-4682-b0dc-6aab64e9d32a",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- Spike probability correlates linear with a drop in regret performance\n",
    "- Spikes quickly lead to the model believing that there is one, and converging to the wrong treatment\n",
    "  - Problem is less present in ConjugateNormalModel, after some data, it will converge back\n",
    "\n",
    "### Identified problems:\n",
    "- Spikes in data might lead to convergence to condition without treatment effect\n",
    "- Spikes in data might lead to long phases with testing a poor condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5c622-78fc-46ef-a287-2b6f9b2a174b",
   "metadata": {},
   "source": [
    "## Scenario 5: All together\n",
    "All combinations of two effects and all three effects from Scenarios 2-4 together, to test if there are any interaction effects. I choose Ramp Up as the baseline change, cause this was doing the most harm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9a1f4-1367-4fef-90ba-f974ebaaecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generating_model_5_1 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    "    correlation=0.7,\n",
    ")\n",
    "data_generating_model_5_2 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    spike_probability=2.0 / 7,\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    ")\n",
    "data_generating_model_5_3 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    spike_probability=2.0 / 7,\n",
    "    correlation=0.7,\n",
    ")\n",
    "data_generating_model_5_4 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    spike_probability=2.0 / 7,\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    "    correlation=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73a603-8222-4292-9bf8-b717c89287aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_designs = {\n",
    "    \"n_patients\": [N_PATIENTS],\n",
    "    \"policy\": [fixed_policy, linear_ts, beta_ts],\n",
    "    \"model_from_patient_id\": [\n",
    "        data_generating_model_5_1,\n",
    "        data_generating_model_5_2,\n",
    "        data_generating_model_5_3,\n",
    "        data_generating_model_5_4,\n",
    "    ],\n",
    "}\n",
    "configurations = generate_configuration_cross_product(study_designs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17bca44-26f1-41d3-90b5-fd245cccfb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_series, config_to_simulation_data = simulate_configurations(\n",
    "    configurations, LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc1b441-065c-46b7-a0ba-36c00e8e2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result_table(calculated_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06efec-f739-4529-b532-e219ccd258cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regret_against_fixed(calculated_series, config_to_simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e159079-235f-481e-94c1-c9a471a4f28f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_allocations_for_calculated_series(calculated_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31bded-f9ec-4f0c-b9f5-845ff92ce932",
   "metadata": {},
   "source": [
    "### Results\n",
    "- General decrease in performance in Regret\n",
    "- Correlation & Spikes lead to high variability in outcome\n",
    "- Ramp Up + X leads to big drop in performance\n",
    "  - BetaModel performs the bad with RampUp and Correlation\n",
    "  - Conjugate Model performs worst with all three influences\n",
    "- Big \"swing\" at t~15 for BetaModel with RampUp and Correlation\n",
    "  - Probably due to average changing through new observations and then sudden changes in calculated probabilities\n",
    "\n",
    "### Identified problems:\n",
    "- Correlation & Spikes lead to high variability in outcome\n",
    "- Trend towards the wrong condition with different interfering factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e05b1e-a592-479f-af78-401d66b1d66d",
   "metadata": {},
   "source": [
    "## Mitigation\n",
    "\n",
    "### List of identified problems:\n",
    "#### Scenario 2\n",
    "- Models converge if there is no treatment effect\n",
    "- Models converge on the wrong treatment effect (mostly present in Beta Model). \n",
    "#### Scenario 4\n",
    "- Spikes in data might lead to convergence to condition without treatment effect\n",
    "- Spikes in data might lead to long phases with testing a poor condition\n",
    "#### Scenario 5\n",
    "- Correlation & Spikes lead to high variability in outcome\n",
    "- Trend towards the wrong condition with different interfering factors\n",
    "\n",
    "### Mitigation strategies\n",
    "- Clipping\n",
    "Fixing the max probability for one condition, so that the model can not \"endlessly converge\".\n",
    "- Sliding Window\n",
    "Only analyzing x newest datapoints, so that old data is not incorporated.\n",
    "- Starting Balanced\n",
    "Starting the experiment with a fixed ABAB design, and only then starting ThompsonSampling.\n",
    "\n",
    "### Test scenarios\n",
    "We test against all inferences, once with no intervention effect and once with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbce66-803b-4da4-afca-5f74f47288fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_policy = FixedPolicy(number_of_actions=N_INTERVENTIONS)\n",
    "clipped_linear_ts = ClippedThompsonSampling(\n",
    "    inference_model=ConjugateNormalModel(**conjugate_normal_model_priors),\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "clipped_beta_ts = ClippedThompsonSampling(\n",
    "    inference_model=BetaModel(),\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "fixed_start_linear_ts = ComposedPolicy(\n",
    "    policies=[\n",
    "        FixedPolicy(number_of_actions=N_INTERVENTIONS),\n",
    "        ThompsonSampling(\n",
    "            inference_model=ConjugateNormalModel(**conjugate_normal_model_priors),\n",
    "            number_of_actions=N_INTERVENTIONS,\n",
    "        ),\n",
    "    ],\n",
    "    durations=[4, 100],\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "fixed_start_beta_ts = ComposedPolicy(\n",
    "    policies=[\n",
    "        FixedPolicy(number_of_actions=N_INTERVENTIONS),\n",
    "        ThompsonSampling(\n",
    "            inference_model=BetaModel(),\n",
    "            number_of_actions=N_INTERVENTIONS,\n",
    "        ),\n",
    "    ],\n",
    "    durations=[4, 100],\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "\n",
    "sliding_linear_ts = ThompsonSampling(\n",
    "    inference_model=SlidingModel(\n",
    "        sliding_window_size=15,\n",
    "        model=ConjugateNormalModel(**conjugate_normal_model_priors),\n",
    "    ),\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "\n",
    "sliding_beta_ts = ThompsonSampling(\n",
    "    inference_model=SlidingModel(sliding_window_size=15, model=BetaModel()),\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95c87d-7b88-4cc7-ba46-f771c0faf69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generating_model_6_1 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    spike_probability=2.0 / 7,\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    "    correlation=0,\n",
    ")\n",
    "data_generating_model_6_2 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 0],\n",
    "    spike_probability=2.0 / 7,\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    "    correlation=0,\n",
    ")\n",
    "data_generating_model_6_3 = lambda patient_id: SelfExperimentationModel(\n",
    "    patient_id,\n",
    "    intervention_effects=[0, 1],\n",
    "    spike_probability=2.0 / 7,\n",
    "    baseline_model=\"linear\",\n",
    "    baseline_config={\"start\": 10, \"end\": 30, \"min\": -1, \"max\": 1, \"name\": \"Ramp Up\"},\n",
    "    correlation=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a99dca-cf34-4652-a4fa-8727b4f928cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_designs = {\n",
    "    \"n_patients\": [N_PATIENTS],\n",
    "    \"policy\": [\n",
    "        fixed_policy,\n",
    "        linear_ts,\n",
    "        beta_ts,\n",
    "        clipped_linear_ts,\n",
    "        clipped_beta_ts,\n",
    "        fixed_start_beta_ts,\n",
    "        fixed_start_linear_ts,\n",
    "        sliding_linear_ts,\n",
    "        sliding_beta_ts,\n",
    "    ],\n",
    "    \"model_from_patient_id\": [\n",
    "        data_generating_model_6_1,\n",
    "        data_generating_model_6_2,\n",
    "        data_generating_model_6_3,\n",
    "    ],\n",
    "}\n",
    "configurations = generate_configuration_cross_product(study_designs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cace89-60b7-4b9a-aad1-ca33947ed61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_series, config_to_simulation_data = simulate_configurations(\n",
    "    configurations, LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b014f64-e753-4d8e-a95e-3d3dd2d32a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result_table(calculated_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e53ce-4b92-41a3-8191-29d900b0d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regret_against_fixed(calculated_series, config_to_simulation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbb2ef-6b5d-47d0-90ab-103f63054b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allocations_for_calculated_series(calculated_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca97dcb-10b3-4a87-9026-a45839e12a28",
   "metadata": {},
   "source": [
    "### Results\n",
    "- Clipping:\n",
    "  - Without correlation: Improves prediction\n",
    "  - With correlation: Only small effect: Prevents really long sequences, but end decision is not touched, (probably because due to correlation only switching shortly does not make a difference)\n",
    "  - We see that it prevents always sampling the wrong condition (no \"lock in\")\n",
    "- Sliding Window:\n",
    "  - No clear benefits\n",
    "- Balanced Start:\n",
    "  -  Increases correct prediction at end of trial\n",
    "  -  Increases variance (counter-intuitive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b4b32-6b23-407a-8096-c423dfba8295",
   "metadata": {},
   "source": [
    "### Combining what we learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3f3ba-52c6-421f-bc90-8d1dbc10ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \"The ultimate thompson sampling\"\n",
    "ultimate_ts = ComposedPolicy(\n",
    "    policies=[\n",
    "        FixedPolicy(number_of_actions=N_INTERVENTIONS),\n",
    "        ClippedThompsonSampling(\n",
    "            inference_model=ConjugateNormalModel(**conjugate_normal_model_priors),\n",
    "            number_of_actions=N_INTERVENTIONS,\n",
    "        ),\n",
    "    ],\n",
    "    durations=[4, 100],\n",
    "    number_of_actions=N_INTERVENTIONS,\n",
    ")\n",
    "study_designs = {\n",
    "    \"n_patients\": [N_PATIENTS],\n",
    "    \"policy\": [fixed_policy, ultimate_ts, beta_ts],\n",
    "    \"model_from_patient_id\": [\n",
    "        data_generating_model_1_1,\n",
    "        data_generating_model_1_2,\n",
    "        data_generating_model_1_3,\n",
    "        data_generating_model_2_1,\n",
    "        data_generating_model_2_2,\n",
    "        data_generating_model_2_3,\n",
    "        data_generating_model_3_1,\n",
    "        data_generating_model_3_2,\n",
    "        data_generating_model_3_3,\n",
    "        data_generating_model_4_1,\n",
    "        data_generating_model_4_2,\n",
    "        data_generating_model_4_3,\n",
    "        data_generating_model_5_1,\n",
    "        data_generating_model_5_2,\n",
    "        data_generating_model_5_3,\n",
    "        data_generating_model_6_1,\n",
    "        data_generating_model_6_2,\n",
    "        data_generating_model_6_3,\n",
    "    ],\n",
    "}\n",
    "configurations = generate_configuration_cross_product(study_designs)\n",
    "calculated_series, config_to_simulation_data = simulate_configurations(\n",
    "    configurations, LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ec59f-1824-4ab2-b85f-a00ddf0558fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_result_table(calculated_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183219d-03b2-4da4-b8df-72fb78919ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_allocations_for_calculated_series(calculated_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edada70-38b4-4358-9b96-be4437ab8944",
   "metadata": {},
   "source": [
    "## Results\n",
    "- model has similar performance in regret, but much better performance in pointing out the correct intervention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99af00-3c73-4d7b-ac43-9dff472913fd",
   "metadata": {},
   "source": [
    "## Learnings\n",
    "Behavior of Thomspons Sampling is different, heavily interactive between simulation model and chosen implementation.\n",
    "E.g. clipping: One might think it would decrease the variability in performance, but it does not always in our experiments.\n",
    "\n",
    "### New model\n",
    "I propose implementing a model that randomizes to a balanced design for the first 4 datapoints, either ABAB or BABA, and then start with ClippedThompsonSampling with a normal model:\n",
    "- Easy to update due to conjugate prior, which means we can use simple math and don't need to sample\n",
    "- Easy to calculate probabilities, we only need to sample two distribution\n",
    "- Is able to \"understand\" the magnitude of change in the data\n",
    "#### Potential shortcomings:\n",
    "- model assumes some \"linearity\" on the scale of results, which is not always given\n",
    "- clipping will force some exploration even when the data is perfectly clear\n",
    "\n",
    "\n",
    "### Open questions:\n",
    "\n",
    "- Can such a model provide better user experience? --> Ultimately only testable in a user study, I think this could be interesting, but not sure if we want to go that route\n",
    "\n",
    "- How can data labelling help? --> We discussed a lot if it would help if users could \"label\" data to be influenced not by the condition, but by something else, and are outliers. The first thing that comes to mind is a weighted linear regression, but it is not really clear how to transfer this into a Bayesian Approach (for a fun read, see Andrew Gelman discussing if weights are Bayesian and should be allowed in stan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027416d-f817-4ba7-995a-68cf3f556f4e",
   "metadata": {},
   "source": [
    "## Additional code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
